(INFO) 2024-05-18 14:24:07,508 - Panacea_train_logger:
Args Info:
--task_name Panacea_train
--n_save_step 1
--output_dir ./output
--accelertor_cfg_log_with None
--accelertor_cfg_gradient_accumulation_steps 2
--dateset_cfg_data_path /home/smliu/datasets/hf/hh-rlhf
--dateset_cfg_sub_data_path ['harmless-base']
--dateset_cfg_tokenizer_pretrain_path /home/share/models/huggingface/meta-llama/Llama-2-7b-chat-hf
--dateset_cfg_max_len 512
--dateset_cfg_remove_chinese True
--dateset_cfg_padding_side left
--dateset_cfg_prompt_only False
--dateset_cfg_tokenize_type prompt_not_pad
--model_cfg_model_pretrain_path /home/share/models/huggingface/meta-llama/Llama-2-7b-chat-hf
--model_cfg_model_class None
--model_cfg_peft_cfg_adapter_name svd_lora_altered
--model_cfg_peft_cfg_target_modules ['q_proj', 'k_proj', 'v_proj', 'out_proj']
--model_cfg_peft_cfg_r 6
--model_cfg_peft_cfg_pref_r 1
--model_cfg_peft_cfg_lora_alpha 32
--model_cfg_peft_cfg_lora_dropout 0.0
--model_cfg_peft_cfg_pref_dim 2
--model_cfg_peft_cfg_init_strategy diag_zero
--model_cfg_ckpt_path ./ckpts
--model_cfg_use_ckpt False
--model_cfg_ckpt_load_path None
--model_cfg_device cuda
--model_cfg_max_len 512
--ref_cfg_model_pretrain_path /home/share/models/huggingface/meta-llama/Llama-2-7b-chat-hf
--ref_cfg_model_class None
--ref_cfg_peft_cfg_adapter_name None
--ref_cfg_peft_cfg_target_modules None
--ref_cfg_ckpt_path ./ckpts
--ref_cfg_use_ckpt False
--ref_cfg_ckpt_load_path None
--ref_cfg_device cuda
--ref_cfg_max_len 512
--lr 0.0001
--critic_lr 0.0001
--weight_decay 0.0005
--pooled_values False
--max_norm None
--kl_ref_coef 0.2
--kl_type kl
--eps_clip 0.2
--value_clip 0.2
--beta_s 0.01
--lam 0.95
--gae_gamma 1
--ratio_threshold 10
--value_loss_coef 0.1
--train_batch_size 2
--n_update_epoch 1
--critic_pretrain_epoch 10
--manipulator_cfg_weighted_loss_type mols
--manipulator_cfg_svd_lora_type None
--manipulator_cfg_svd_lora_random_init None
--manipulator_cfg_svd_lora_split_percentage 0.125
--manipulator_cfg_n_adapt_step 2
--reward_cfg_0_model_pretrain_path /home/smliu/huggingface/Ray2333/gpt2-large-helpful-reward_model
--reward_cfg_0_model_class None
--reward_cfg_0_peft_cfg_adapter_name None
--reward_cfg_0_peft_cfg_target_modules None
--reward_cfg_0_device cuda
--reward_cfg_0_reward_weight 1
--reward_name_0 helpful
--reward_cfg_1_model_pretrain_path /home/smliu/huggingface/Ray2333/gpt2-large-harmless-reward_model
--reward_cfg_1_model_class None
--reward_cfg_1_peft_cfg_adapter_name None
--reward_cfg_1_peft_cfg_target_modules None
--reward_cfg_1_device cuda
--reward_cfg_1_reward_weight 1
--reward_name_1 harmless
--reward_cfg_2_model_pretrain_path None
--reward_cfg_2_model_class None
--reward_cfg_2_peft_cfg_adapter_name None
--reward_cfg_2_peft_cfg_target_modules None
--reward_cfg_2_device cuda
--reward_cfg_2_reward_weight 1
--reward_name_2 None
--reward_scalariztion_type None
--n_episode 1
--sample_batch_size 1
--n_sample_reuse 1
--n_update_timestep 8
--n_eval_epoch 6
--n_eval_sample 4

OrderedDict([('model.embed_tokens', 0), ('model.layers.0', 0), ('model.layers.1', 0), ('model.layers.2', 0), ('model.layers.3', 1), ('model.layers.4', 1), ('model.layers.5', 1), ('model.layers.6', 1), ('model.layers.7', 1), ('model.layers.8', 2), ('model.layers.9', 2), ('model.layers.10', 2), ('model.layers.11', 2), ('model.layers.12', 2), ('model.layers.13', 3), ('model.layers.14', 3), ('model.layers.15', 3), ('model.layers.16', 3), ('model.layers.17', 3), ('model.layers.18', 4), ('model.layers.19', 4), ('model.layers.20', 4), ('model.layers.21', 4), ('model.layers.22', 4), ('model.layers.23', 5), ('model.layers.24', 5), ('model.layers.25', 5), ('model.layers.26', 5), ('model.layers.27', 5), ('model.layers.28', 6), ('model.layers.29', 6), ('model.layers.30', 6), ('model.layers.31', 6), ('model.norm', 6), ('lm_head', 6)])
(INFO) 2024-05-18 14:24:48,426 - Panacea_train_logger:
Peft Info:
total parameters: 6744707840
trainable parameters: 6292224
non-trainable parameters: 6738415616
OrderedDict([('transformer.wte', 0), ('transformer.wpe', 0), ('transformer.drop', 0), ('transformer.h.0', 0), ('transformer.h.1', 1), ('transformer.h.2', 1), ('transformer.h.3', 1), ('transformer.h.4', 1), ('transformer.h.5', 1), ('transformer.h.6', 1), ('transformer.h.7', 2), ('transformer.h.8', 2), ('transformer.h.9', 2), ('transformer.h.10', 2), ('transformer.h.11', 2), ('transformer.h.12', 2), ('transformer.h.13', 3), ('transformer.h.14', 3), ('transformer.h.15', 3), ('transformer.h.16', 3), ('transformer.h.17', 3), ('transformer.h.18', 3), ('transformer.h.19', 4), ('transformer.h.20', 4), ('transformer.h.21', 4), ('transformer.h.22', 4), ('transformer.h.23', 4), ('transformer.h.24', 4), ('transformer.h.25', 5), ('transformer.h.26', 5), ('transformer.h.27', 5), ('transformer.h.28', 5), ('transformer.h.29', 5), ('transformer.h.30', 5), ('transformer.h.31', 6), ('transformer.h.32', 6), ('transformer.h.33', 6), ('transformer.h.34', 6), ('transformer.h.35', 6), ('transformer.ln_f', 6), ('score', 6)])
OrderedDict([('transformer.wte', 0), ('transformer.wpe', 0), ('transformer.drop', 0), ('transformer.h.0', 0), ('transformer.h.1', 1), ('transformer.h.2', 1), ('transformer.h.3', 1), ('transformer.h.4', 1), ('transformer.h.5', 1), ('transformer.h.6', 1), ('transformer.h.7', 2), ('transformer.h.8', 2), ('transformer.h.9', 2), ('transformer.h.10', 2), ('transformer.h.11', 2), ('transformer.h.12', 2), ('transformer.h.13', 3), ('transformer.h.14', 3), ('transformer.h.15', 3), ('transformer.h.16', 3), ('transformer.h.17', 3), ('transformer.h.18', 3), ('transformer.h.19', 4), ('transformer.h.20', 4), ('transformer.h.21', 4), ('transformer.h.22', 4), ('transformer.h.23', 4), ('transformer.h.24', 4), ('transformer.h.25', 5), ('transformer.h.26', 5), ('transformer.h.27', 5), ('transformer.h.28', 5), ('transformer.h.29', 5), ('transformer.h.30', 5), ('transformer.h.31', 6), ('transformer.h.32', 6), ('transformer.h.33', 6), ('transformer.h.34', 6), ('transformer.h.35', 6), ('transformer.ln_f', 6), ('score', 6)])
(INFO) 2024-05-18 14:24:50,363 - Panacea_train_logger:
Disabling target model peft layers as reference model.
(INFO) 2024-05-18 14:24:50,452 - Panacea_train_logger:
shared params: 576
task 0 specific params: 96
task 1 specific params: 96
pretrained_model.model.layers.0.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.0.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.0.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.1.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.1.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.1.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.2.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.2.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.2.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.3.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.3.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.3.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.4.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.4.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.4.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.5.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.5.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.5.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.6.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.6.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.6.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.7.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.7.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.7.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.8.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.8.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.8.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.9.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.9.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.9.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.10.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.10.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.10.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.11.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.11.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.11.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.12.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.12.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.12.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.13.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.13.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.13.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.14.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.14.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.14.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.15.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.15.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.15.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.16.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.16.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.16.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.17.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.17.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.17.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.18.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.18.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.18.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.19.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.19.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.19.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.20.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.20.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.20.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.21.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.21.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.21.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.22.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.22.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.22.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.23.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.23.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.23.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.24.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.24.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.24.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.25.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.25.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.25.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.26.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.26.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.26.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.27.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.27.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.27.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.28.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.28.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.28.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.29.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.29.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.29.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.30.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.30.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.30.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.31.self_attn.q_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.31.self_attn.k_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
pretrained_model.model.layers.31.self_attn.v_proj, ([-1, -1, -1, -1, -1, -1, 0, 1])
(INFO) 2024-05-18 14:24:50,646 - Panacea_train_logger:
Save timesteps:[48].
